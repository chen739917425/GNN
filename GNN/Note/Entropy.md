### 信息熵

$$
H(p) = \sum_{k=1}^{N}p_klog_2\frac{1}{p_k}
$$

* $p_k$表示事件$k$发生的概率，式子可以理解为**采用最优策略来消除系统或随机变量的不确定性，需要猜测的期望次数**
* 信息熵代表的是随机变量或整个系统的不确定性，熵越大，随机变量或系统的不确定性就越大
* 根据真实分布，我们能够找到一个最优策略，以**最小的代价**消除系统的不确定性，而这个代价大小就是信息熵

### 交叉熵

$$
H(p,q) = \sum_{k=1}^{N}p_klog_2\frac{1}{q_k}
$$



* $p_k$为真实分布，$q_k$为非真实分布
* 用来衡量在给定的真实分布下，**使用非真实分布所指定的策略**消除系统的不确定性所需要付出的努力的大小

* 交叉熵的值就越小，说明使用的策略越优，算出的非真实分布越接近真实分布

### 相对熵

$$
KL(p||q) = H(p,q) - H(p) = \sum_{i=k}^{N}p_klog_2\frac{p_k}{q_k}
$$

* 也称作**KL散度**，衡量某个策略的交叉熵与信息熵的差异
* 注意KL散度的**非对称性**

